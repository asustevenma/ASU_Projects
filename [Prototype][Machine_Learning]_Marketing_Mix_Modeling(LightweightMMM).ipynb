{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjyY2h5r0c/PLLgwvO7/Mi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asustevenma/ASU_Projects/blob/master/%5BPrototype%5D%5BMachine_Learning%5D_Marketing_Mix_Modeling(LightweightMMM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **BigQuery Magics**\n",
        "BigQuery magics are used to run BigQuery SQL queries in a python environment.\n",
        "These queries can also be run in the BigQuery UI\n",
        "\n",
        "[Getting started with BigQuery - Colaboratory - Google Colab](https://colab.research.google.com/notebooks/bigquery.ipynb)"
      ],
      "metadata": {
        "id": "h5aNg5zDWFD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Environment**"
      ],
      "metadata": {
        "id": "d56squE6h8Sf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYnWtPRJWZEJ"
      },
      "outputs": [],
      "source": [
        "# SET BigQuery PROJECT ID #\n",
        "project_id = \"app-dmp-light-ga4-dev\"\n",
        "\n",
        "# Google credentials authentication libraries\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "auth.authenticate_user()\n",
        "\n",
        "# BigQuery Magics\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from google.cloud.bigquery import magics\n",
        "\n",
        "magics.context.project = project_id\n",
        "client = bigquery.Client(project=magics.context.project)\n",
        "\n",
        "%load_ext google.cloud.bigquery\n",
        "%load_ext google.colab.data_table\n",
        "bigquery.USE_LEGACY_SQL = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install lightweight_mmm (If you face the error that requests to restart runtime, Click the restart runtime button and re-install it)\n",
        "\n",
        "# !pip install --upgrade pip\n",
        "# !pip install lightweight_mmm\n",
        "\n",
        "# %pip install --upgrade git+https://github.com/google/lightweight_mmm.git"
      ],
      "metadata": {
        "id": "hJlG4NL-0TWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Python Libraries**"
      ],
      "metadata": {
        "id": "FxSE_SmOiK3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_gbq\n",
        "\n",
        "# Modeling and Metrics\n",
        "# import statsmodels.api as sm\n",
        "# from statsmodels.stats.stattools import durbin_watson\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "# Visutalization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# import plotly.express as px"
      ],
      "metadata": {
        "id": "Ur7QJ-JwW-4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import jax.numpy and any other library we might need\n",
        "import jax.numpy as jnp\n",
        "import numpyro\n",
        "\n",
        "# Import the relevant modules of the library\n",
        "from lightweight_mmm import lightweight_mmm\n",
        "from lightweight_mmm import optimize_media\n",
        "from lightweight_mmm import plot\n",
        "from lightweight_mmm import preprocessing\n",
        "from lightweight_mmm import utils"
      ],
      "metadata": {
        "id": "5_JyuQivFMjD",
        "outputId": "70e55ca0-c962-4fa3-f22f-506e7e0bc788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpyro'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c83aea013d9c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import jax.numpy and any other library we might need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpyro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import the relevant modules of the library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpyro'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import the Dataset from BigQuery**"
      ],
      "metadata": {
        "id": "wcxz5sRxhpwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a dataset from BigQuery table into a Pandas Dataframe\n",
        "\n",
        "%%bigquery df_mmm_demo_raw_data\n",
        "\n",
        "# Import a dataset from BigQuery table into a Pandas Dataframe\n",
        "\n",
        "WITH SALES AS (\n",
        "  SELECT\n",
        "    ad_date,\n",
        "    DATE_TRUNC(ad_date, WEEK(SUNDAY)) AS week_of_sale,\n",
        "    SUM(conversion_value)*1000 AS sales_amount\n",
        "  FROM `app-dmp-light-ga4-dev.bi_demo.marketing__ad_performance`\n",
        "  WHERE ad_date BETWEEN DATE(2023, 1, 1) AND DATE(2023, 4, 30)\n",
        "  GROUP BY 1, 2\n",
        "),\n",
        "\n",
        "CHANNEL_GOOGLE AS (\n",
        "  SELECT\n",
        "    DATE_SUB(ad_date, INTERVAL 1 YEAR) AS ad_date,\n",
        "    DATE_TRUNC(DATE_SUB(ad_date, INTERVAL 1 YEAR), WEEK(SUNDAY)) AS week_of_sale,\n",
        "    SUM(impressions) AS impressions_channel_google,\n",
        "    SUM(clicks) AS clicks_channel_google,\n",
        "    SUM(ad_spend) AS ad_spend_channel_google\n",
        "  FROM `app-dmp-light-ga4-dev.transform_abc_mart_vpon.marketing__channel_google_ads`\n",
        "  WHERE DATE_SUB(ad_date, INTERVAL 1 YEAR) BETWEEN DATE(2023, 1, 1) AND DATE(2023, 4, 30)\n",
        "  GROUP BY 1, 2\n",
        "),\n",
        "\n",
        "CHANNEL_FB AS (\n",
        "  SELECT\n",
        "    DATE_SUB(ad_date, INTERVAL 1 YEAR) AS ad_date,\n",
        "    DATE_TRUNC(DATE_SUB(ad_date, INTERVAL 1 YEAR), WEEK(SUNDAY)) AS week_of_sale,\n",
        "    SUM(impressions) AS impressions_channel_fb,\n",
        "    SUM(clicks) AS clicks_channel_fb,\n",
        "    SUM(ad_spend) AS ad_spend_channel_fb\n",
        "  FROM `app-dmp-light-ga4-dev.transform_abc_mart_vpon.marketing__channel_facebook_ads`\n",
        "  WHERE DATE_SUB(ad_date, INTERVAL 1 YEAR) BETWEEN DATE(2023, 1, 1) AND DATE(2023, 4, 30)\n",
        "  GROUP BY 1, 2\n",
        "),\n",
        "\n",
        "CHANNEL_IG AS (\n",
        "  SELECT\n",
        "    ad_date,\n",
        "    DATE_TRUNC(ad_date, WEEK(SUNDAY)) AS week_of_sale,\n",
        "    SUM(impressions)*5 AS impressions_channel_ig,\n",
        "    SUM(clicks)*5 AS clicks_channel_ig,\n",
        "    SUM(ad_spend)*5 AS ad_spend_channel_ig\n",
        "  FROM `app-dmp-light-ga4-dev.bi_demo.marketing__ad_performance`\n",
        "  WHERE ad_channel = \"line\"\n",
        "    AND ad_date BETWEEN DATE(2023, 1, 1) AND DATE(2023, 4, 30)\n",
        "  GROUP BY 1, 2\n",
        "),\n",
        "\n",
        "TW_HOLIDAY AS (\n",
        "  SELECT\n",
        "    DATE(holiday_date) AS holiday_date,\n",
        "    holiday_name\n",
        "  FROM `app-dmp-light-ga4-dev.data_at_bqml.holidays_by_country`\n",
        "  WHERE country_code = \"TW\"\n",
        "  GROUP BY 1, 2\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  SALES.ad_date,\n",
        "  EXTRACT(MONTH FROM SALES.week_of_sale) AS month_of_sale,\n",
        "  ROW_NUMBER() OVER (PARTITION BY EXTRACT(MONTH FROM SALES.week_of_sale) ORDER BY EXTRACT(WEEK FROM SALES.week_of_sale)) AS week_of_month,\n",
        "  IF(holiday_name IS NOT NULL, 1, 0) AS is_holiday,\n",
        "  impressions_channel_google,\n",
        "  impressions_channel_fb,\n",
        "  impressions_channel_ig,\n",
        "  ad_spend_channel_google,\n",
        "  ad_spend_channel_fb,\n",
        "  ad_spend_channel_ig,\n",
        "  sales_amount\n",
        "FROM SALES\n",
        "LEFT JOIN CHANNEL_GOOGLE\n",
        "  ON SALES.ad_date = CHANNEL_GOOGLE.ad_date\n",
        "LEFT JOIN CHANNEL_FB\n",
        "  ON SALES.ad_date = CHANNEL_FB.ad_date\n",
        "LEFT JOIN CHANNEL_IG\n",
        "  ON SALES.ad_date = CHANNEL_IG.ad_date\n",
        "LEFT JOIN TW_HOLIDAY\n",
        "  ON SALES.ad_date = TW_HOLIDAY.holiday_date\n",
        "ORDER BY 1, 2\n",
        ";"
      ],
      "metadata": {
        "id": "DX93mIM7hnJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mmm_demo_raw_data[\"ad_date\"] = pd.to_datetime(df_mmm_demo_raw_data[\"ad_date\"])\n",
        "df_mmm_demo_raw_data.info()"
      ],
      "metadata": {
        "id": "M2akg9OAYwpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "IbaFlFHPSol5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(15,6))\n",
        "# heatmap = sns.heatmap(df_mmm_demo_raw_data[[\"ad_spend_channel_google\", \"ad_spend_channel_fb\", \"ad_spend_channel_ig\", \"sales_amount\"]].corr(), annot=True, cmap=\"Blues\")"
      ],
      "metadata": {
        "id": "KA74OrT3jVtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.pairplot(df_mmm_demo_raw_data[[\"ad_spend_channel_google\", \"ad_spend_channel_fb\", \"ad_spend_channel_ig\", \"sales_amount\"]])"
      ],
      "metadata": {
        "id": "Q8yf_gXRTJpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LightweightMMM**\n",
        "\n",
        "[LightweightMMM Documentation](https://lightweight-mmm.readthedocs.io/en/latest/index.html#)\n",
        "\n",
        "[Lightweight (Bayesian) Marketing Mix Modeling](https://github.com/google/lightweight_mmm)\n",
        "\n",
        "Reference -> [Simple End to End Demo Script](https://github.com/takechanman1228/mmm_pydata_global_2022/blob/main/simple_end_to_end_demo_pydataglobal.ipynb)"
      ],
      "metadata": {
        "id": "hpktp9Hz0JrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing**"
      ],
      "metadata": {
        "id": "susFI0mt7QBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split Training and Testing Data**"
      ],
      "metadata": {
        "id": "uIUCMTpzqra-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since it is time series data, we need to split training data and test data by date\n",
        "split_point = pd.Timestamp(\"2023-04-01\")\n",
        "\n",
        "df_mmm_demo_data_train = df_mmm_demo_raw_data.loc[df_mmm_demo_raw_data[\"ad_date\"] < split_point]\n",
        "df_mmm_demo_data_test = df_mmm_demo_raw_data.loc[df_mmm_demo_raw_data[\"ad_date\"] >= split_point]"
      ],
      "metadata": {
        "id": "XQvWPLfLtGuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media data:\n",
        "# Containing the metric per channel and time span (eg. impressions per time period). Media values must not contain negative values.\n",
        "\n",
        "media_data_train = df_mmm_demo_data_train[[\"impressions_channel_google\",\n",
        "                                           \"impressions_channel_fb\",\n",
        "                                           \"impressions_channel_ig\"\n",
        "                                           ]].fillna(0).to_numpy().astype(\"float64\")\n",
        "media_data_test = df_mmm_demo_data_test[[\"impressions_channel_google\",\n",
        "                                         \"impressions_channel_fb\",\n",
        "                                         \"impressions_channel_ig\"\n",
        "                                         ]].fillna(0).to_numpy().astype(\"float64\")"
      ],
      "metadata": {
        "id": "RpejSoMA3nEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Data:\n",
        "# Any other features that one might want to add to the analysis.\n",
        "\n",
        "extra_data_train = df_mmm_demo_data_train[[\"month_of_sale\", \"week_of_month\", \"is_holiday\"]].to_numpy().astype(\"float64\")\n",
        "extra_data_test = df_mmm_demo_data_test[[\"month_of_sale\", \"week_of_month\", \"is_holiday\"]].to_numpy().astype(\"float64\")"
      ],
      "metadata": {
        "id": "sXWcdBNE7KVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cost Data:\n",
        "# The total cost per media unit per channel.\n",
        "\n",
        "cost_data_train = df_mmm_demo_data_train[[\"ad_spend_channel_google\",\n",
        "                                          \"ad_spend_channel_fb\",\n",
        "                                          \"ad_spend_channel_ig\"\n",
        "                                          ]].sum().to_numpy().astype(\"float64\")\n",
        "cost_data_test = df_mmm_demo_data_test[[\"ad_spend_channel_google\",\n",
        "                                        \"ad_spend_channel_fb\",\n",
        "                                        \"ad_spend_channel_ig\"\n",
        "                                        ]].sum().to_numpy().astype(\"float64\")"
      ],
      "metadata": {
        "id": "_25VHQXn7Ud5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Data:\n",
        "# Target KPI for the model to predict. For example, revenue amount, number of app installs.\n",
        "\n",
        "target_data_train = df_mmm_demo_data_train[\"sales_amount\"].fillna(0).to_numpy().astype(\"float64\")\n",
        "target_data_test = df_mmm_demo_data_test[\"sales_amount\"].fillna(0).to_numpy().astype(\"float64\")"
      ],
      "metadata": {
        "id": "Xx33gzTH7bLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scale the Data**"
      ],
      "metadata": {
        "id": "_3bJ3nrFq2ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare scaler\n",
        "media_data_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "extra_data_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "cost_data_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean, multiply_by=0.25) # , multiply_by=0.15\n",
        "target_data_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "\n",
        "\n",
        "# Scale the data\n",
        "media_data_train_scaled = media_data_scaler.fit_transform(media_data_train)\n",
        "extra_data_train_scaled = extra_data_scaler.fit_transform(extra_data_train)\n",
        "cost_data_train_scaled = cost_data_scaler.fit_transform(cost_data_train)\n",
        "target_data_train_scaled = target_data_scaler.fit_transform(target_data_train)\n",
        "\n",
        "media_data_test_scaled = media_data_scaler.fit_transform(media_data_test)\n",
        "extra_data_test_scaled = extra_data_scaler.fit_transform(extra_data_test)"
      ],
      "metadata": {
        "id": "N12Whi3wtfVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign Media(Channel) Name\n",
        "media_names = [\"Google\", \"Facebook\", \"Instagram\"]"
      ],
      "metadata": {
        "id": "i1_6Wg2uNbV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Tuning**\n",
        "\n",
        "The currently available models are the following:\n",
        "- hill_adstock\n",
        "- adstock\n",
        "- carryover"
      ],
      "metadata": {
        "id": "xtPRVU0Y6Xk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Up Hyperparameters\n",
        "\n",
        "SEED = 105\n",
        "number_warmup=1000\n",
        "number_samples=1000\n",
        "adstock_models = [\"adstock\", \"hill_adstock\", \"carryover\"] # , \"carryover\"\n",
        "degrees_season = [1,2,3]\n",
        "\n",
        "list_model_name = []\n",
        "list_degree = []\n",
        "list_mape = []\n",
        "tuning_results = {}"
      ],
      "metadata": {
        "id": "-rWq_3SPxBcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "for model_name in adstock_models:\n",
        "  for degrees in degrees_season:\n",
        "    mmm_model_tune = lightweight_mmm.LightweightMMM(model_name=model_name)\n",
        "    mmm_model_tune.fit(\n",
        "        media=media_data_train_scaled,  # Media input data\n",
        "        media_prior=cost_data_train_scaled,  # Costs of each media channel\n",
        "        target=target_data_train_scaled,  # Target KPI to use\n",
        "        extra_features=extra_data_train_scaled,  # Other variables to add to the model\n",
        "        number_warmup=number_warmup,\n",
        "        number_samples=number_samples,\n",
        "        number_chains=2,  # Number of chains to sample. Default is 2\n",
        "        degrees_seasonality=degrees,  # Number of degrees to use for seasonality. Default is 2\n",
        "        weekday_seasonality=True,  # In case of daily data, also estimate seven weekday parameters\n",
        "        seasonality_frequency=365,  # Frequency of the time period used. Default is 52 as in 52 weeks per year\n",
        "        media_names=media_names,  # Names of the media channels passed\n",
        "        seed=SEED\n",
        "        )\n",
        "\n",
        "    mmm_predictions_tune = mmm_model_tune.predict(\n",
        "        media=media_data_test_scaled,\n",
        "        extra_features=extra_data_test_scaled,\n",
        "        # media_gap=0,\n",
        "        target_scaler=target_data_scaler,\n",
        "        seed=SEED\n",
        "        )\n",
        "\n",
        "    prediction_tune = np.mean(mmm_predictions_tune, axis=0)\n",
        "\n",
        "    mape = mean_absolute_percentage_error(target_data_test, prediction_tune)\n",
        "    # print(f\"model_name={model_name} degrees={degrees} MAPE={mape} samples={prediction_tune[:3]}\")\n",
        "\n",
        "    list_model_name.append(model_name)\n",
        "    list_degree.append(degrees)\n",
        "    list_mape.append(mape)\n",
        "\n",
        "\n",
        "tuning_results[\"model_name\"] = list_model_name\n",
        "tuning_results[\"degrees\"] = list_degree\n",
        "tuning_results[\"mape\"] = list_mape"
      ],
      "metadata": {
        "id": "YZn0GlZV83es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Training**"
      ],
      "metadata": {
        "id": "2P_2jak-cjCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess all data for retrain\n",
        "\n",
        "media_data_all = df_mmm_demo_raw_data[[\"impressions_channel_google\",\n",
        "                                       \"impressions_channel_fb\",\n",
        "                                       \"impressions_channel_ig\"\n",
        "                                      ]].fillna(0).to_numpy().astype(\"float64\")\n",
        "\n",
        "extra_data_all = df_mmm_demo_raw_data[[\"month_of_sale\", \"week_of_month\", \"is_holiday\"]].to_numpy().astype(\"float64\")\n",
        "\n",
        "cost_data_all = df_mmm_demo_raw_data[[\"ad_spend_channel_google\",\n",
        "                                      \"ad_spend_channel_fb\",\n",
        "                                      \"ad_spend_channel_ig\"\n",
        "                                    ]].sum().to_numpy().astype(\"float64\")\n",
        "\n",
        "target_data_all = df_mmm_demo_raw_data[\"sales_amount\"].fillna(0).to_numpy().astype(\"float64\")"
      ],
      "metadata": {
        "id": "7EJRtsw-GUvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare scaler for all the data\n",
        "\n",
        "media_data_scaler_all = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "extra_data_scaler_all = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "cost_data_scaler_all = preprocessing.CustomScaler(divide_operation=jnp.mean, multiply_by=0.25) # , multiply_by=0.15\n",
        "target_data_scaler_all = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
        "\n",
        "# Scale all the data\n",
        "\n",
        "media_data_all_scaled = media_data_scaler_all.fit_transform(media_data_all)\n",
        "extra_data_all_scaled = extra_data_scaler_all.fit_transform(extra_data_all)\n",
        "cost_data_all_scaled = cost_data_scaler_all.fit_transform(cost_data_all)\n",
        "target_data_all_scaled = target_data_scaler_all.fit_transform(target_data_all)"
      ],
      "metadata": {
        "id": "Do7AQtFLFo1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the model for all data based on the results of hyperparameter tuning\n",
        "\n",
        "min_pos = tuning_results[\"mape\"].index(min(tuning_results[\"mape\"]))\n",
        "\n",
        "mmm_model = lightweight_mmm.LightweightMMM(model_name=tuning_results[\"model_name\"][min_pos])\n",
        "mmm_model.fit(\n",
        "    media=media_data_all_scaled,\n",
        "    media_prior=cost_data_all_scaled,\n",
        "    target=target_data_all_scaled,\n",
        "    extra_features=extra_data_all_scaled,\n",
        "    number_warmup=number_warmup,\n",
        "    number_samples=number_samples,\n",
        "    number_chains=2,\n",
        "    degrees_seasonality=tuning_results[\"degrees\"][min_pos],\n",
        "    weekday_seasonality=True,\n",
        "    seasonality_frequency=365,\n",
        "    media_names=media_names,\n",
        "    seed=SEED\n",
        "    )"
      ],
      "metadata": {
        "id": "mV-3giL72-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Evaluation & Insights**"
      ],
      "metadata": {
        "id": "hUU9rnQ0C1s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mmm_model.print_summary()"
      ],
      "metadata": {
        "id": "2F2MD2Cl9t0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the ground truth, predicted value and interval for the training data.\n",
        "\n",
        "plot.plot_model_fit(\n",
        "    media_mix_model=mmm_model,\n",
        "    target_scaler=target_data_scaler_all,\n",
        "    interval_mid_range=0.9\n",
        "    )"
      ],
      "metadata": {
        "id": "-z2JcM2fC7OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It estimates the media contribution percentage and ROI of each channel.\n",
        "# If data was scaled prior to training then the target and costs scalers need to be passed to this function to correctly calculate media contribution percentage and ROI in the unscaled space.\n",
        "\n",
        "media_contribution, roi_hat = mmm_model.get_posterior_metrics(\n",
        "    unscaled_costs=None,\n",
        "    target_scaler=target_data_scaler_all,\n",
        "    cost_scaler=cost_data_scaler_all\n",
        "    )\n",
        "\n",
        "df_roi_hat = pd.DataFrame(roi_hat, columns=[\"Google\", \"Facebook\", \"Instagram\"])\n",
        "df_media_contribution = pd.DataFrame(media_contribution, columns=[\"Google\", \"Facebook\", \"Instagram\"])"
      ],
      "metadata": {
        "id": "EBck12F6nNXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots a barchart of estimated media effects with their percentile interval.\n",
        "# The ROI plot takes into account not only the media effect but how much it costs to get this effect.\n",
        "\n",
        "plot.plot_bars_media_metrics(\n",
        "    metric=roi_hat,\n",
        "    metric_name=\"ROI Hat\",\n",
        "    channel_names=media_names\n",
        "    )"
      ],
      "metadata": {
        "id": "wKCLRv1gIDqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots a barchart of estimated media effects with their percentile interval.\n",
        "# Visualize the estimated contribution of each media channel\n",
        "\n",
        "plot.plot_bars_media_metrics(\n",
        "    metric=media_contribution,\n",
        "    metric_name=\"Media Contribution Percentage\",\n",
        "    channel_names=media_names\n",
        "    )"
      ],
      "metadata": {
        "id": "G9JZXcaDME6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The media effects plot shows an estimate of the coefficients for each media channel. High numbers mean the channel influenced the revenue more.\n",
        "# The x-axis is the estimated coefficient, the y-axis can be seen as how confident the model is that the x-axis value is the right value for the media effect.\n",
        "\n",
        "plot.plot_media_channel_posteriors(\n",
        "    media_mix_model=mmm_model,\n",
        "    channel_names=media_names,\n",
        "    quantiles=(0.05, 0.5, 0.95),\n",
        "    fig_size=None\n",
        "    )"
      ],
      "metadata": {
        "id": "7lM7G9SmC6yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots an area chart to visualize weekly media & baseline contribution.\n",
        "# We can quickly visualize the estimated media & baseline contribution over time.\n",
        "\n",
        "plot.plot_media_baseline_contribution_area_plot(media_mix_model=mmm_model,\n",
        "                                                target_scaler=target_data_scaler_all,\n",
        "                                                channel_names=media_names,\n",
        "                                                fig_size=(25,15)\n",
        "                                                )"
      ],
      "metadata": {
        "id": "UiIgja2FDOFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the response curves of each media channel based on the model.\n",
        "# Visualize how each media channel behaves individually as we invest more in it\n",
        "\n",
        "plot.plot_response_curves(\n",
        "    media_mix_model=mmm_model,\n",
        "    media_scaler=media_data_scaler_all,\n",
        "    target_scaler=target_data_scaler_all,\n",
        "    seed=SEED\n",
        "    )"
      ],
      "metadata": {
        "id": "2hyj7GhMMPO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Prediction on out-of-sample Data**"
      ],
      "metadata": {
        "id": "nVL2h5qFDY2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the test/out-of-sampe data if we have not done so\n",
        "\n",
        "mmm_predictions = mmm_model.predict(\n",
        "    media=media_data_test,\n",
        "    extra_features=extra_data_test_scaled,\n",
        "    target_scaler=target_data_scaler_all,\n",
        "    seed=SEED)\n",
        "\n",
        "prediction_array = np.mean(mmm_predictions, axis=0)"
      ],
      "metadata": {
        "id": "vKv2_6MZDbwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mmm_demo_data_test[\"prediction\"] = prediction_array.tolist()"
      ],
      "metadata": {
        "id": "ObnZJMTAvHlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape_test_data = mean_absolute_percentage_error(target_data_test, prediction_array)\n",
        "print(f\"MAPE={mape_test_data} samples={prediction_array[:3]}\")"
      ],
      "metadata": {
        "id": "S1DMVGQs_e5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the ground truth, predicted value and interval for the test data.\n",
        "\n",
        "plot.plot_out_of_sample_model_fit(\n",
        "    out_of_sample_predictions=mmm_predictions,\n",
        "    out_of_sample_target=target_data_test,\n",
        "    interval_mid_range=0.9\n",
        "    )"
      ],
      "metadata": {
        "id": "MjGnWB3pbj23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Budget Optimization**\n",
        "\n",
        "The optimization is meant to solve the budget allocation questions for you. First you need to provide for how long you want to optimize your budget (eg. 15 weeks).\n",
        "\n",
        "The optimization values will be bounded by +- 20% of the max and min historic values used for training. Which means the optimization won't recommend to completely change your strategy but how to make some budget re-allocation.\n",
        "\n",
        "Prices are the average price you would expect for the media units of each channel. If your data is already a money unit (eg. $) your prices should be an array of 1s."
      ],
      "metadata": {
        "id": "GqyV6UXDkMpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run media optimization.\n",
        "\n",
        "estimate_budget = 800000  # The budget you want to allocate for the next n_time_periods\n",
        "estimate_prices = np.array([0.1, 0.11, 0.12])  # Price per media unit per channel"
      ],
      "metadata": {
        "id": "6YPG_IEglEES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run optimization with the parameters of choice.\n",
        "\n",
        "solution, kpi_without_optim, previous_media_allocation = optimize_media.find_optimal_budgets(\n",
        "    n_time_periods=extra_data_test_scaled.shape[0],  # The number of time periods you want to simulate\n",
        "    media_mix_model=mmm_model,\n",
        "    extra_features=extra_data_test_scaled,\n",
        "    budget=estimate_budget,\n",
        "    prices=estimate_prices,\n",
        "    media_scaler=media_data_scaler_all,\n",
        "    target_scaler=target_data_scaler_all,\n",
        "    seed=SEED\n",
        "    )"
      ],
      "metadata": {
        "id": "u2VRT93ioKMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your media data is not in money unit (eg. impressions, clicks, GRPs, etc.), you would need to store the cost per values (eg. CPC) in the prices array and multiply it by solution.x to get the recommended budget allocation."
      ],
      "metadata": {
        "id": "jFpNSfv7sDh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the optimal weekly allocation.\n",
        "optimal_buget_allocation = estimate_prices * solution.x\n",
        "\n",
        "# Similar renormalization to get previous budget allocation\n",
        "previous_budget_allocation = estimate_prices * previous_media_allocation"
      ],
      "metadata": {
        "id": "-llsWoGioAO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_budget_allocation = {}\n",
        "dict_budget_allocation[\"ad_channel\"] = media_names\n",
        "dict_budget_allocation[\"previous_budget_allocation\"] = previous_budget_allocation.tolist()\n",
        "dict_budget_allocation[\"optimal_buget_allocation\"] = optimal_buget_allocation.tolist()\n",
        "df_budget_allocation = pd.DataFrame.from_dict(dict_budget_allocation)"
      ],
      "metadata": {
        "id": "4RKljwdhtTqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Both values should be very close in order to compare KPI\n",
        "estimate_budget, optimal_buget_allocation.sum()"
      ],
      "metadata": {
        "id": "KMp3ev24st2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pre_post_optimization = {\n",
        "    \"pre_post_optimization\": [\"pre_optimization_predicted_target\", \"post_optimization_predicted_target\"],\n",
        "    \"pre_post_optimization_value\": [-kpi_without_optim.item(), -solution[\"fun\"]]\n",
        "}\n",
        "\n",
        "df_pre_post_optimization = pd.DataFrame(dict_pre_post_optimization)"
      ],
      "metadata": {
        "id": "aqRrFVQmZL8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot out pre post optimization budget allocation and predicted target variable comparison.\n",
        "# The graph shows the previous budget allocation and optimized budget allocation\n",
        "\n",
        "plot.plot_pre_post_budget_allocation_comparison(\n",
        "    media_mix_model=mmm_model,\n",
        "    kpi_with_optim=solution[\"fun\"],\n",
        "    kpi_without_optim=kpi_without_optim,\n",
        "    optimal_buget_allocation=optimal_buget_allocation,\n",
        "    previous_budget_allocation=previous_budget_allocation,\n",
        "    figure_size=(10,10),\n",
        "    channel_names=media_names\n",
        "    )"
      ],
      "metadata": {
        "id": "8WU7NbKqtFh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save Predictions to BigQuery Table**"
      ],
      "metadata": {
        "id": "k74Qwa3uRLOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_contribution = plot.create_media_baseline_contribution_df(\n",
        "    media_mix_model=mmm_model,\n",
        "    target_scaler=target_data_scaler_all,\n",
        "    channel_names=media_names\n",
        "    )\n",
        "\n",
        "df_contribution.columns = df_contribution.columns.str.replace(\" \", \"_\")\n",
        "df_date = df_mmm_demo_raw_data[[\"ad_date\"]].drop_duplicates().sort_values(by=[\"ad_date\"], ignore_index=True)\n",
        "df_contribution_date = pd.merge(df_contribution, df_date, left_index=True, right_index=True). #\n"
      ],
      "metadata": {
        "id": "93H0Y7pXv3BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dataframe of budget optimization into a BigQuery table\n",
        "\n",
        "table_id = \"data_at_bqml.lightweightmmm_budget_optimization\"\n",
        "pandas_gbq.to_gbq(dataframe=df_budget_allocation, destination_table=table_id, project_id=project_id, if_exists=\"replace\")"
      ],
      "metadata": {
        "id": "ZvZKDOyXQ564"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dataframe of out-of-sample predictions into a BigQuery table\n",
        "\n",
        "table_id = \"data_at_bqml.lightweightmmm_prediction\"\n",
        "pandas_gbq.to_gbq(dataframe=df_mmm_demo_data_test, destination_table=table_id, project_id=project_id, if_exists=\"replace\")"
      ],
      "metadata": {
        "id": "BhE_Zjo4zJFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dataframe of contribution into a BigQuery table\n",
        "\n",
        "table_id = \"data_at_bqml.lightweightmmm_contribution\"\n",
        "pandas_gbq.to_gbq(dataframe=df_contribution_date, destination_table=table_id, project_id=project_id, if_exists=\"replace\")"
      ],
      "metadata": {
        "id": "rqmbX-ralWM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dataframe of pre/post budget optimization into a BigQuery table\n",
        "\n",
        "table_id = \"data_at_bqml.lightweightmmm_pre_post_optimization\"\n",
        "pandas_gbq.to_gbq(dataframe=df_pre_post_optimization, destination_table=table_id, project_id=project_id, if_exists=\"replace\")"
      ],
      "metadata": {
        "id": "UCi3g-jqbP9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dataframe of ROI hat into a BigQuery table\n",
        "\n",
        "table_id = \"data_at_bqml.lightweightmmm_roi_hat\"\n",
        "pandas_gbq.to_gbq(dataframe=df_roi_hat, destination_table=table_id, project_id=project_id, if_exists=\"replace\")"
      ],
      "metadata": {
        "id": "XKD5QOMRh2an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Dataframe of media contribution percentage into a BigQuery table\n",
        "\n",
        "table_id = \"data_at_bqml.lightweightmmm_media_contribution_pct\"\n",
        "pandas_gbq.to_gbq(dataframe=df_media_contribution, destination_table=table_id, project_id=project_id, if_exists=\"replace\")"
      ],
      "metadata": {
        "id": "Zw8JoIjCiWjO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}